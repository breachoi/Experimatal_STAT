---
title: "Choi_STAT6301_HW3"
output:
  pdf_document: default
  html_document:
    df_print: paged
date: "2024-09-24"
format:
  html:
    toc: true
    embed-resources: true
    code-fold: true
    code-line-numbers: true
    code-summary: homework code
    code-tools: true
    theme: yeti
editor: visual
---

# Question1

-   Part A\
    -   samples are drawn from a normal distributed population.
    -   The shape of two graphs have reasonable same shape.
    -   The observation in the sample are independent of one another.
    -   The data come from a random sample.

```{r a}
knitr::include_graphics("C:/Users/choih/OneDrive/Desktop/hw3q1.jpg")
knitr::include_graphics("C:/Users/choih/OneDrive/Desktop/hw3q1_2.jpg")
```

-   Part B\

```{r b}
#| include: false
library(Sleuth3)
```

```{r c}
#| include: false
#' Credit: Volodymyr Orlov
#' https://github.com/VolodymyrOrlov/MSDS6371/blob/master/shade.r

#' Draws a t-distribution curve and shades rejection regions
#' 
#' @param df degrees of freedom.
#' @param alpha significance level
#' @param h0 null hypothesis value
#' @param sides one of: both, left, right
#' @param t_calc calculated test statistics
#' @examples
#' shade(49, 0.05, 0, t_calc=1.1)
shade <- function(df, alpha, h0 = 0, sides='both', t_calc=NULL) {
  e_alpha = alpha
  if(sides == 'both'){
    e_alpha = alpha / 2
  }
  cv = abs(qt(e_alpha, df))
  curve(dt(x, df), from = -4, to = 4, ylab='P(x)', xaxt='n') 
  abline(v = 0, col = "black", lwd = 0.5)
  labels = h0
  at = 0
  if(sides == 'both' | sides == 'left'){
    x <- seq(-4, -abs(cv), len = 100) 
    y <- dt(x, df)
    polygon(c(x, -abs(cv)), c(y, min(y)), col = "blue", border = NA)
    lines(c(-cv, -cv), c(0, dt(-cv, df)), col = "black", lwd = 1)
    text(-cv - (4 - cv) / 2, 0.05, e_alpha)
    labels = c(round(-cv, 3), labels)
    at = c(-cv, at)
  }
  if(sides == 'both' | sides == 'right'){
    x <- seq(abs(cv), 4, len = 100)
    y <- dt(x, df)
    polygon(c(abs(cv), x), c(min(y), y), col = "blue", border = NA)
    lines(c(cv, cv), c(0, dt(cv, df)), col = "black", lwd = 1)
    text(cv + (4 - cv) / 2, 0.05, e_alpha)
    labels = c(labels, round(cv, 3))
    at = c(at, cv)
  }
  if(is.numeric(t_calc)){
    abline(v = t_calc, col = "red", lwd = 2)
    text(t_calc + 0.5, 0.2, t_calc, col = "red")
  }
  axis(1, at=at, labels=labels)
}
```

```{r d}
age <- read.csv('C:/Users/choih/OneDrive/Desktop/age_discrim2024.csv')
age$status <- factor(age$status)


par(mfrow=c(2,2))

qqnorm(age$age[age$status=="fired"], main='fired')
qqline(age$age[age$status=="fired"])

qqnorm(age$age[age$status=="not.fired"], main='not.fired')
qqline(age$age[age$status=="not.fired"])

hist(age$age[age$status=="fired"], xlab='Status', main='fired')
box()
hist(age$age[age$status=="not.fired"], xlab='Status', main='not.fired')
box()

boxplot(age ~ status, data=age, horizontal=T,
main='Boxplots of age, by status')

qt(0.95, 58, lower.tail=T)

##Note we use alternative='less' since R orders alphabetically and thus tests Man - Woman
##i.e. testing Man - Woman  < 0 is equivalent to testing Woman - Man > 0
t.test(age ~ status, data=age, alternative='less', var.equal=T)

##To switch the levels for the test (temporarily)
##Note this forces us to change the alternative
t.test(age ~ relevel(status, ref='fired'), data=age, 
alternative='greater', var.equal=T)

##To permanently change the reference level
age$status <- relevel(age$status, ref='fired')
t.test(age ~ status, data=age, alternative='greater', var.equal=T)
```

-   Part C\

    1.  State the problem.

        $$ H_0: \mu_{\text{fired}} > \mu_{\text{notfired}} $$ $$ H_A: \mu_{\text{fired}} < \mu_{\text{notfired}}   $$($\alpha\ = 0.05$ )

        -   Test the claim that age affects employed status

    2.  Address the assumptions of t-test (from part A).

        -   Judging from the histograms and QQ plots, there is significant visual evidence to suggest the data come from normal distributions. However, since the sample size is reasonable, the t-test is robust to this assumption. Also, we will assume that these data are independent.

    3.  Perform the t-test if it is appropriate and a permutation test if it is not (judging from you analysis of the assumptions).

```{r e}
    knitr::include_graphics("C:/Users/choih/OneDrive/Desktop/hw3q1_3.jpg")
```

```         
4.  Provide a conclusion including the p-value and a confidence interval.
    -   There is sufficient evidence to not support claim at the $\alpha$ = 0.05 level of significance(p =0.2882) that the mean score of those who were fired is different from the mean age of those who were not fired. A 95% one-sided confidence interval for this difference is (-1.5939, 5.2511).
5.  Provide the scope of inference.
    -   Since the study collected the sample of employees randomly, we can generalize the inference to all employed people by this particular company.
```

# Question2

-   Part A\

    -   samples are drawn from a right-skewed distributions population.
    -   The shape of two graphs are way different shape.
    -   The observation in the sample are independent of one another.
    -   The data come from a random sample.

```{r f}
    money <- read.csv('C:/Users/choih/OneDrive/Desktop/money_poll2024.csv')
    money$name <- factor(money$name)


    par(mfrow=c(2,2))

    qqnorm(money$money[money$name=="SMU"], main='SMU')
    qqline(money$money[money$name=="SMU"])

    qqnorm(money$money[money$name=="SeattleU"], main='SeattleU')
    qqline(money$money[money$name=="SeattleU"])

    hist(money$money[money$name=="SMU"], xlab='Poket money', main='SMU')
    box()
    hist(money$money[money$name=="SeattleU"], xlab='Poket money', main='SeattleU')
    box()

    boxplot(money ~ name, data=money, horizontal=T,
    main='Boxplots of money, by student')

    qt(0.95, 58, lower.tail=T)

    ##Note we use alternative='less' since R orders alphabetically and thus tests Man - Woman
    ##i.e. testing Man - Woman  < 0 is equivalent to testing Woman - Man > 0
    t.test(money ~ name, data=money, alternative='less', var.equal=T)

    ##To switch the levels for the test (temporarily)
    ##Note this forces us to change the alternative
    t.test(money ~ relevel(name, ref='SMU'), data=money, 
    alternative='greater', var.equal=T)

    ##To permanently change the reference level
    money$name <- relevel(money$name, ref='SMU')
    t.test(money ~ name, data=money, alternative='greater', var.equal=T)
```

```{r g}
knitr::include_graphics("C:/Users/choih/OneDrive/Desktop/hw3q2.jpg")
knitr::include_graphics("C:/Users/choih/OneDrive/Desktop/hw3q2_2.jpg")
```

-   Part B\

    1.  State the problem. $$ H_0: \mu_{\text{SMU}} = \mu_{\text{SeattleU}}$$ $$ H_A: \mu_{\text{SMU}} \ne \mu_{\text{SeattleU}}$$

        -   Test the claim that mean amount of pocket money of the SMU students is different than that of the students from SeattleU.

    2.  Address the assumptions of t-test (from part A).

        -   Judging from the histogram and box plots, there is significant visual evidence that the standard deviations are different. In addition, since the sample sizes are small we know that the t-test is not robust to this assumption\

    3.  Perform the t-test if it is appropriate and a permutation test if it is not (judging from you analysis of the assumptions).

        -   Since I was not address assumption of t-test of this study I applied permutation test.

```{r h}
        money_poll <- read.csv("C:/Users/choih/OneDrive/Desktop/money_poll2024.csv")

        t.test(money_poll$money ~ money_poll$name)
        number_of_permutation <- 50000
        xbarholder <- numeric(0)
        counter <- 0

        observed_diff <- mean(subset(money_poll, name=="SMU")$money)-mean(subset(money_poll, name=="SeattleU")$money)

        for(i in 1:number_of_permutation)
        {
          scramble <- sample(money_poll$money, 30)
          
          smu <- scramble[1:16]
          seattle <- scramble[17:30]
          
          diff <- mean(smu) - mean(seattle)
          
          xbarholder[i] <- diff
          
          if(abs(diff) > abs(observed_diff))
          counter <- counter +1
        }

        hist(xbarholder)
        pvalue <- counter / number_of_permutation
        #xbarholder[which(abs(xbarholder)>observed_diff)]
        pvalue
```

```         
4.  Provide a conclusion including the p-value and a confidence interval.

    -   There is sufficient evidence to not support claim at the $\alpha$ = 0.05 level of significance(p =0.14) that the mean score of those who were student at SMU is different from the mean amount of money who were student at SeattleU. A 95% one-sided confidence interval for this difference is (-288.42239, 44.67239).

5.  Provide the scope of inference

    -   Since the subjects in this sample were not randomly sampled, the results only finarlized to the subjects in the study.
```

-   Part C\

    -   After checking the assumptions without the outlier, there is no difference between with or without. this study still cannot apply t-test. the p-value with an outlier is 0.1592 and without is 0.1421. Compared to those two values, it is hard to say that are different. So, the outlier does not affect to change the conclusion.

# Question3

```{r i}
education <- read.csv("C:/Users/choih/OneDrive/Desktop/EducationData6301.csv")
Educ$Income2005 <- factor(Educ$Income2005)
education$log.Income2005 <- log(education$Income2005)
par(mfrow=c(2,2))

hist(subset(education, Educ=='12')$Income2005, main='Income2005', xlab='Income2005')
hist(subset(education, Educ=='16')$Income2005, main='Income2005', xlab='Income2005')
qqnorm(subset(education, Educ=='12')$Income2005)
qqnorm(subset(education, Educ=='16')$Income2005)

par(mfrow=c(2,2))
hist(subset(education, Educ=='12')$log.Income2005, main='Income2005', xlab='Log Income2005')
hist(subset(education, Educ=='16')$log.Income2005, main='Income2005', xlab='Log Income2005')
qqnorm(subset(education, Educ=='12')$log.Income2005)
qqnorm(subset(education, Educ=='16')$log.Income2005)

##Be careful! Pay attention to which groups are being subtracted
##The test statistic is negative, so this implies unseeded - seeded
##In our alternative hypothesis, we hope to show seeded > unseeded
##So, our alternative here should be unseeded - seeded < 0
t.test(log.Income2005 ~ Educ, data=education, var.equal=T, alternative='less')

```

-   State the problem.
    -   Test the claim that Education level affects the income.

$$ H_0: \mu_{\text{12}} > \mu_{\text{16}} $$ $$ H_A: \mu_{\text{12}} < \mu_{\text{16}} $$($$\alpha\ = 0.05$$ )

-   Address the assumptions of t-test (from part A).

    -   Judging from the histograms and QQ plots, there is significant visual evidence to suggest the data come from normal distributions. However, since the sample size is reasonable, the t-test is robust to this assumption. Also, we will assume that these data are independent.

-   Perform the t-test if it is appropriate and a permutation test if it is not (judging from you analysis of the assumptions).

```{r}
education <- read.csv("C:/Users/choih/OneDrive/Desktop/EducationData6301.csv")
Educ$Income2005 <- factor(Educ$Income2005)
par(mfrow=c(2,2))

hist(subset(education, Educ=='12')$Income2005, main='Income2005', xlab='Income2005')
hist(subset(education, Educ=='16')$Income2005, main='Income2005', xlab='Income2005')
qqnorm(subset(education, Educ=='12')$Income2005)
qqnorm(subset(education, Educ=='16')$Income2005)

##Be careful! Pay attention to which groups are being subtracted
##The test statistic is negative, so this implies unseeded - seeded
##In our alternative hypothesis, we hope to show seeded > unseeded
##So, our alternative here should be unseeded - seeded < 0
t.test(Income2005 ~ Educ, data=education, var.equal=T, alternative='less')

##For a 2-sided CI
t.test(Income2005 ~ Educ, data=education, var.equal=T, conf.level=0.95)
```

-   Provide a conclusion including the p-value and a confidence interval.

    -   There is sufficient evidence to support claim at the $\alpha$ = 0.05 level of significance(p =2.2e-16). The median that money of income those who were 16 years study is 0.6201834 bigger than who were studied 12 years. A 95% confidence interval for this multiplicative effect is 0 to 0.68.

-   Provide the scope of inference

    -   Since the subjects in this sample were randomly sampled, we can generalize the inference to this study.
